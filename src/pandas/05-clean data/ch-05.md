# Cleaning Data

### methods for cleaning data

- `df.shape` A two-element tuple indicating the number of rows and columns in a data frame.
  
```python
df.shape
```

- `len(df)` or `len(df.index)` Gets the number of rows in a data frame.

```python
len(df)
len(df.index)
```

- `s.isnull()` Returns a boolean series indicating where there are null (typically NaN) values in the series `s`

```python
s.isnull()
```

- `s.notnull()` Returns a boolean series indicating where there are not null (typically NaN) values in the series `s`

```python
s.notnull()
```

- `df.isnull()` Returns a boolean data frame indicating where there are null (typically NaN) values in the data frame `df`

```python
df.isnull()
```

- `df.replace()` Replaces values in one or more columns with other values

```python
df.replace(to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad', axis=None, **kwargs)
```

- `s.map()` Applies a function to each element of a series, returning the result of that application on each element

```python
s.map(lambda x: x.upper())
```

- `df.fillna()` Replaces NaN with other values

```python
df.fillna(10)
```

- `df.dropna()` Removes rows with NaN values

```python
df.dropna()
```

- `s.str` Works with textual data

```python
df['colname'].str
```

- `str.isdigit()` Returns a boolean series, indicating which strings contain only the digits 0–9

```python
df['colname'].str.isdigit()
```

- `pd.to_numeric()` Returns a series of integers or floats based on a series of strings

```python
pd.to_numeric(df['colname'])
```

- `df.sort_index()` Reorders the rows of a data frame based on the values in its index in ascending order

```python
df = df.sort_index()
```

- `s.value_counts()` Returns a sorted (descending frequency) series counting how many times each value appears in `s`

```python
s.value_counts()
```

- `s.unique()` Returns a series with the unique (i.e., distinct) values in `s`, including NaN (if it occurs in `s`)

```python
s.unique()
```

- `s.mode()` Returns a series with the most commonly found values in `s`

```python
s.mode()
```

#### how many NaN values are in a given column?

**count** method you can run on a series, which returns the number of non-null values in the series.
That combined with the shape of the series, you can figure out how many `NaN` values there are.

```python
s.shape[0] - s.count()
```

**isnull()** method returns a boolean series with `True` for every `NaN` value in the series.

```python
s.isnull().sum()    # calculate the sum of the NaN values in the series
```

If you run `isnull` on a data frame, you get a new data frame back, with `True` and `False` values indicating whether there is a null value in that particular row-column.
combination.

```python
df.isnull().sum()   # calculate the sum of the NaN values in each column
```

**How many rows are in the data frame when it is read into memory?**

```python
len(df.index)
```

However, as I said earlier, I prefer to call `len(df.index)`, which gives me the total length and seems to run fastest.

**Remove rows with any missing data (i.e., a `NaN` value). How many rows remain after doing this pruning?** 

```python
all_good_df = df.dropna() # drop the rows with NaN values
len(all_good_df.index)
```

#### Finding numeric strings

we can turn a string column into an integer column with

```python
df['colname'] = df['colname'].astype(np.int64)
```

However, this will fail if any of the rows in df['colname'] cannot be turned into integers.

We can determine which rows in a column can be successfully turned into integers by applying the `isdigit` method via the `str` accessor:

```python
df['colname'] = df['colname'].str.isdigit()
```
This returns a boolean series in which `True` values correspond with NaN in `df['colname']` and False values correspond to non-NaN values in df['colname']. This boolean series can then be applied as a mask index to the original column.


#### Inconsistent data
when the same value is represented by several different values.
for example, the database column for “country” contained all of the following values: `USA`, `US`, `United States`, `United States of America`, and `America`.

**How many different colors are there?**
**value_counts** is a fantastic method for getting the unique values from a series, determining how often each value appears, and sorting them from most to least common. Because `value_counts` returns a series, we can ask for its index and call `len` on it.


```python
len(df['Vehicle Color'].value_counts().index)
```

```python
# Prepare a Python dict in which the keys represent the various color-name inputs, 
# and the values represent the values that you want them to have in the end. 
# I suggest aiming to use the longer names, such as `WHITE`, rather than the shorter ones.

colormap = {'WH': 'WHITE', 'GY':'GRAY',
'BK':'BLACK', 'BL':'BLUE',
'RD':'RED', 'GR':'GRAY',
'TN':'TAN', 'BR':'BROWN',
'YW':'YELLO', 'BLK':'BLACK',
'GRY':'GRAY', 'WHT':'WHITE',
'WHI':'WHITE', 'OR':'ORANG',
'BK.':'BLACK', 'WT':'WHITE',
'WT.':'WHITE'}
```

```python
# Replace the existing (old) colors with color translations.  
df['Vehicle Color'] = df['Vehicle Color'].replace(colormap)
```
















